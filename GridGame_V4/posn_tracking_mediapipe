import cv2
import mediapipe as mp

# init pose model
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(
    static_image_mode=False,
    model_complexity=1,
    enable_segmentation=False,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# Video capture from webcam
cap = cv2.VideoCapture(0)

# Store init position
initial_x = None
initial_z = None

# Define physical movement to tile step ratio
lateral_step = 0.05  # 1 tile = 5% screen width (X movement)
depth_step = 0.05    # Z movement

while cap.isOpened():
    success, frame = cap.read()
    if not success:
        print("Camera read failed.")
        break

    frame = cv2.flip(frame, 1)  # Mirror for natural interaction
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(rgb_frame)

    if results.pose_landmarks:
        landmarks = results.pose_landmarks.landmark
        left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]
        right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]

        # Average hip center (x: lateral, z: depth)
        x = (left_hip.x + right_hip.x) / 2 # left/right movement 
        z = (left_hip.z + right_hip.z) / 2  # forwards/backwards movement

        # init zero-point on first detection
        if initial_x is None or initial_z is None:
            initial_x = x
            initial_z = z

        dx = x - initial_x
        dz = z - initial_z

        # Convert to virtual grid steps
        tile_x = int(dx / lateral_step)
        tile_y = int(dz / depth_step)

        print(f" Grid Position: ({tile_x}, {tile_y})")

        # draw skeleton
        mp.solutions.drawing_utils.draw_landmarks(
            frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

    # Display feed
    cv2.imshow('Pose Grid Tracking', frame)

    # ESC to exit
    if cv2.waitKey(1) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()
